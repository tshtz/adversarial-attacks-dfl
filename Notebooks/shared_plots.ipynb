{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e92497c5",
   "metadata": {},
   "source": [
    "# Some Plots for the Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91411f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR\"] = \"False\"\n",
    "import mlflow \n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import sys\n",
    "from helpers import get_transferability_data_from_mlflow, get_threshold_val, get_attacker_regret_errors\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c8fd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also create a column for the attacker_sig\n",
    "# Helper function to safely get parameter values\n",
    "def safe_get_param(row, param_name, default=\"None\"):\n",
    "    if param_name in row and pd.notna(row[param_name]):\n",
    "        return str(row[param_name])\n",
    "    return default\n",
    "\n",
    "def format_str_to_same_length(inp1, inp2, inp3, padding1, padding2, padding3):\n",
    "    len_1 = len(inp1)\n",
    "    len_2 = len(inp2)\n",
    "    len_3 = len(inp3)\n",
    "    # pad all of them using _\n",
    "    inp1 = inp1 + \"_\" * (padding1 - len_1)\n",
    "    inp2 = inp2 + \"_\" * (padding2 - len_2)\n",
    "    inp3 = inp3 + \"_\" * (padding3 - len_3)\n",
    "    # return one string\n",
    "    return f\"{inp1}_{inp2}_{inp3}\"\n",
    "\n",
    "def insert_spacers(z, labels, group_keys):\n",
    "    new_z = []\n",
    "    new_labels = []\n",
    "    prev_key = None\n",
    "\n",
    "    group_id = 0\n",
    "    for i, (row, label, key) in enumerate(zip(z, labels, group_keys)):\n",
    "        if prev_key is not None and key != prev_key:\n",
    "            new_z.append([np.nan] * z.shape[1])  # insert blank row\n",
    "            new_labels.append(f\"Group: {group_id+1}\")                # blank label\n",
    "            group_id += 1\n",
    "        new_z.append(row)\n",
    "        new_labels.append(label)\n",
    "        prev_key = key\n",
    "\n",
    "    return np.array(new_z), new_labels\n",
    "\n",
    "def load_data(dataset_name):\n",
    "    dataset_name = dataset_name + \"_Models\"\n",
    "    # TODO: Adjust to your experiment id\n",
    "    experiment_id = \"228319214249946667\"\n",
    "    # Get all the models with img_size 12 -> get a list of run ids\n",
    "    runs = mlflow.search_runs(experiment_ids=experiment_id)\n",
    "    # Filter for finished\n",
    "    runs = runs[runs[\"status\"] == \"FINISHED\"]\n",
    "    # Filter for dataset_name\n",
    "    runs = runs[runs[\"params.attacked_models_experiment\"] == dataset_name]\n",
    "    # Assert that all models have been attacked\n",
    "    runs[\"attacker_sig\"] = runs.apply(lambda row: \n",
    "        row[\"params.attacker\"] + \n",
    "        \"_e\" + safe_get_param(row, \"params.epsilon\") +\n",
    "        \"_a\" + safe_get_param(row, \"params.alpha\") +\n",
    "        \"_m\" + safe_get_param(row, \"params.max_iter\") +\n",
    "        \"_r\" + safe_get_param(row, \"params.restarts\") +\n",
    "        (\"_s\" + safe_get_param(row, \"params.use_signed_grad\") if \"params.use_signed_grad\" in row else \"\"), \n",
    "        axis=1)\n",
    "    # In case of warcraft change the attacked_models_name\n",
    "    if dataset_name == \"Warcraft_Models\":\n",
    "        runs[\"params.attacked_models_name\"] = runs[\"params.attacked_models_name\"].apply(lambda x: x.replace(\"_regret\", \"\"))\n",
    "    runs[\"model_epsilon\"] = runs[\"params.attacked_models_name\"].astype(str) + \"_eps=\" + runs[\"params.epsilon\"].astype(str)\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b7594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the kp data\n",
    "kp_data = load_data(\"Knapsack\")\n",
    "spp_data = load_data(\"ShortestPath\")\n",
    "wcsp_data = load_data(\"Warcraft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19a104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_dict = {\n",
    "    'baseline_mse' : \"PF\",\n",
    "    'baseline':  \"PF\",\n",
    "    'SPO' : \"SPO\",\n",
    "    'DBB' : \"DBB\",\n",
    "    \"IMLE\" : \"IMLE\",\n",
    "    'FenchelYoung' : \"FY\",\n",
    "    \"DCOL\" : \"QPTL\",\n",
    "    'IntOpt' : \"IntOpt\",\n",
    "    'CachingPO_listwise' : \"Listwise\",\n",
    "    'CachingPO_pairwise' : \"Pairwise\",\n",
    "    'CachingPO_pairwise_diff' : \"PairwiseDiff\",\n",
    "    'CachingPO_MAP_c' : \"MAP\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeefbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "# Define model order\n",
    "model_order = [\"PF\", \"SPO\", \"DBB\", \"IMLE\", \"FY\", \"QPTL\", \"IntOpt\", \"Listwise\", \"Pairwise\", \"PairwiseDiff\", \"MAP\"]\n",
    "\n",
    "def process_dataset(data, problem_name):\n",
    "    \"\"\"Process a dataset and return FRRE dictionaries and plot data\"\"\"\n",
    "    frre_0025 = {}\n",
    "    frre_005 = {}\n",
    "    frre_01 = {}\n",
    "    \n",
    "    # First filter only for medium attack budget\n",
    "    data = data[(data[\"params.max_iter\"] == \"100\") | (data[\"params.max_iter\"].isna()) | (data[\"params.max_iter\"] == \"50\")]\n",
    "    \n",
    "    # For each of the datasets -> group by attacked_model_run_id and epsilon\n",
    "    data_grouped = data.groupby([\"params.attacked_models_run_id\", \"params.epsilon\"])\n",
    "    \n",
    "    for (attacked_model_run_id, epsilon), group in data_grouped:\n",
    "        modelname = model_name_dict[group[\"params.attacked_models_name\"].values[0]]\n",
    "        # Get the run id with the highest mean relative regret error\n",
    "        idx_max = group[\"metrics.mean_rel_regret\"].idxmax()\n",
    "        attacker_run_id = group.loc[idx_max, \"run_id\"]\n",
    "        attacker_name = group.loc[idx_max, \"params.attacker\"]\n",
    "        \n",
    "        # Now for the given attacker_run_id -> download the frre errors\n",
    "        rre_clean, are_clean, rre_adv, are_adv, frre_adv = get_attacker_regret_errors(attacker_run_id, problem=problem_name)\n",
    "        \n",
    "        if epsilon == \"0.025\":\n",
    "            assert attacked_model_run_id not in frre_0025, f\"Duplicate entry for {attacked_model_run_id} with epsilon {epsilon}\"\n",
    "            frre_0025[attacked_model_run_id] = (f\"{modelname}\", frre_adv)\n",
    "        elif epsilon == \"0.05\":\n",
    "            assert attacked_model_run_id not in frre_005, f\"Duplicate entry for {attacked_model_run_id} with epsilon {epsilon}\"\n",
    "            frre_005[attacked_model_run_id] = (f\"{modelname}\", frre_adv)\n",
    "        elif epsilon == \"0.1\":\n",
    "            assert attacked_model_run_id not in frre_01, f\"Duplicate entry for {attacked_model_run_id} with epsilon {epsilon}\"\n",
    "            frre_01[attacked_model_run_id] = (f\"{modelname}\", frre_adv)\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected epsilon value: {epsilon}\")\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    plot_data = []\n",
    "    # Process each epsilon value - include all possible epsilon values\n",
    "    epsilon_configs = [\n",
    "        (\"0.025\", frre_0025, \"ε = 0.025\"),\n",
    "        (\"0.05\", frre_005, \"ε = 0.05\"),  # Changed label to include (8)\n",
    "        (\"0.1\", frre_01, \"ε = 0.1\"),\n",
    "    ]\n",
    "    \n",
    "    for epsilon_val, epsilon_dict, epsilon_label in epsilon_configs:\n",
    "        for model_id, (modelname, frre_values) in epsilon_dict.items():\n",
    "            # Add each FRRE value as a separate row\n",
    "            for frre_val in frre_values:\n",
    "                # Fix epsilon=8 positioning to be same as 0.05 (second position)\n",
    "                epsilon_numeric = 0.05 if epsilon_val == \"8\" else float(epsilon_val)\n",
    "                plot_data.append({\n",
    "                    'modelname': modelname,\n",
    "                    'epsilon': epsilon_label,\n",
    "                    'frre_value': frre_val,\n",
    "                    'epsilon_numeric': epsilon_numeric\n",
    "                })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_plot = pd.DataFrame(plot_data)\n",
    "    if not df_plot.empty:\n",
    "        # Sort by epsilon for consistent ordering\n",
    "        df_plot = df_plot.sort_values('epsilon_numeric')\n",
    "        # Create categorical column for model ordering\n",
    "        df_plot['modelname'] = pd.Categorical(df_plot['modelname'], categories=model_order, ordered=True)\n",
    "        df_plot = df_plot.sort_values(['epsilon_numeric', 'modelname'])\n",
    "    \n",
    "    return df_plot\n",
    "\n",
    "# Process all datasets\n",
    "kp_plot_data = process_dataset(kp_data, \"Knapsack\")\n",
    "spp_plot_data = process_dataset(spp_data, \"ShortestPath\")\n",
    "\n",
    "# Create subplots with minimal spacing\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=[\"Knapsack\", \"Shortest Path\"],\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.07  # Minimize space between plots\n",
    ")\n",
    "\n",
    "# Colors for epsilon values - epsilon=8 uses same color as epsilon=0.05\n",
    "colors = {\n",
    "    'ε = 0.025': '#1f77b4', \n",
    "    'ε = 0.05': '#ff7f0e',  # Same color for both 0.05 and 8\n",
    "    'ε = 0.1': '#2ca02c'\n",
    "}\n",
    "\n",
    "# Add boxplots for each dataset\n",
    "datasets = [\n",
    "    (kp_plot_data, 1),\n",
    "    (spp_plot_data, 2), \n",
    "]\n",
    "\n",
    "# Keep track of which epsilon values we've added to legend\n",
    "added_to_legend = set()\n",
    "\n",
    "for df_plot, row in datasets:\n",
    "    if not df_plot.empty:\n",
    "        for epsilon in df_plot['epsilon'].unique():\n",
    "            epsilon_data = df_plot[df_plot['epsilon'] == epsilon]\n",
    "            \n",
    "            for modelname in epsilon_data['modelname'].unique():\n",
    "                model_data = epsilon_data[epsilon_data['modelname'] == modelname]\n",
    "                \n",
    "                # Only show in legend if not already added\n",
    "                show_in_legend = epsilon not in added_to_legend\n",
    "                if show_in_legend:\n",
    "                    added_to_legend.add(epsilon)\n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Box(\n",
    "                        y=model_data['frre_value'],\n",
    "                        name=epsilon,\n",
    "                        x=[str(modelname)] * len(model_data),  # Ensure string for categorical\n",
    "                        marker_color=colors[epsilon],\n",
    "                        legendgroup=epsilon,\n",
    "                        showlegend=show_in_legend,\n",
    "                        offsetgroup=epsilon,\n",
    "                    ),\n",
    "                    row=row, col=1\n",
    "                )\n",
    "\n",
    "# Update layout with legend at bottom\n",
    "fig.update_annotations(font=dict(size=10))\n",
    "fig.update_layout(\n",
    "    boxmode='group',\n",
    "    template=\"plotly_white\",\n",
    "    width=600,\n",
    "    height=350,  # Reduced height since we minimized spacing\n",
    "    showlegend=True,\n",
    "    legend=dict(\n",
    "        orientation=\"h\",  # Horizontal legend\n",
    "        yanchor=\"top\",\n",
    "        y=-0.15,  # Position below the plots\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,  # Center the legend\n",
    "        title_text=\"Attack Magnitude\",\n",
    "        font=dict(size=10),  # Legend entries\n",
    "    ),\n",
    "    margin=dict(\n",
    "        l=10,   # Left margin\n",
    "        r=10,   # Right margin (reduced since legend is inside plot area)\n",
    "        t=20,   # Top margin\n",
    "        b=30    # Bottom margin (for x-axis label)\n",
    "    ),\n",
    ")\n",
    "fig.update_xaxes(tickfont_size=10)\n",
    "fig.update_yaxes(tickfont_size=10)\n",
    "\n",
    "# Update axes - shared y-axis title on middle subplot only # change size to 10\n",
    "fig.update_yaxes(title_text=\"FRRE\")\n",
    "fig.update_xaxes(title_text=\"Model\", row=2)\n",
    "\n",
    "# Set categorical x-axis ordering for all subplots\n",
    "for row in [1, 2]:\n",
    "    fig.update_xaxes(categoryorder='array', categoryarray=model_order, row=row)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Adjust this to your desired path\n",
    "path = \"\"\n",
    "fig.write_image(path, format=\"pdf\", width=600, height=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e1ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model order\n",
    "model_order = [\"PF\", \"SPO\", \"DBB\", \"IMLE\", \"FY\", \"Listwise\", \"Pairwise\", \"PairwiseDiff\", \"MAP\"]\n",
    "\n",
    "def process_dataset(data, problem_name):\n",
    "    \"\"\"Process a dataset and return FRRE dictionaries and plot data\"\"\"\n",
    "    frre_8 = {}\n",
    "    \n",
    "    # First filter only for medium attack budget\n",
    "    data = data[(data[\"params.max_iter\"] == \"100\") | (data[\"params.max_iter\"].isna()) | (data[\"params.max_iter\"] == \"50\")]\n",
    "    \n",
    "    # For each of the datasets -> group by attacked_model_run_id and epsilon\n",
    "    data_grouped = data.groupby([\"params.attacked_models_run_id\", \"params.epsilon\"])\n",
    "    \n",
    "    for (attacked_model_run_id, epsilon), group in data_grouped:\n",
    "        modelname = model_name_dict[group[\"params.attacked_models_name\"].values[0]]\n",
    "        # Get the run id with the highest mean relative regret error\n",
    "        idx_max = group[\"metrics.mean_rel_regret\"].idxmax()\n",
    "        attacker_run_id = group.loc[idx_max, \"run_id\"]\n",
    "        attacker_name = group.loc[idx_max, \"params.attacker\"]\n",
    "        \n",
    "        # Now for the given attacker_run_id -> download the frre errors\n",
    "        rre_clean, are_clean, rre_adv, are_adv, frre_adv = get_attacker_regret_errors(attacker_run_id, problem=problem_name)\n",
    "        \n",
    "        if epsilon == \"8\":\n",
    "            assert attacked_model_run_id not in frre_8, f\"Duplicate entry for {attacked_model_run_id} with epsilon {epsilon}\"\n",
    "            frre_8[attacked_model_run_id] = (f\"{modelname}\", frre_adv)\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected epsilon value: {epsilon}\")\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    plot_data = []\n",
    "    # Process each epsilon value - include all possible epsilon values\n",
    "    epsilon_configs = [\n",
    "        (\"8\", frre_8, \"ε = 8\"),\n",
    "    ]\n",
    "    \n",
    "    for epsilon_val, epsilon_dict, epsilon_label in epsilon_configs:\n",
    "        for model_id, (modelname, frre_values) in epsilon_dict.items():\n",
    "            # Add each FRRE value as a separate row\n",
    "            for frre_val in frre_values:\n",
    "                # Fix epsilon=8 positioning to be same as 0.05 (second position)\n",
    "                epsilon_numeric = float(epsilon_val)\n",
    "                plot_data.append({\n",
    "                    'modelname': modelname,\n",
    "                    'epsilon': epsilon_label,\n",
    "                    'frre_value': frre_val,\n",
    "                    'epsilon_numeric': epsilon_numeric\n",
    "                })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_plot = pd.DataFrame(plot_data)\n",
    "    if not df_plot.empty:\n",
    "        # Sort by epsilon for consistent ordering\n",
    "        df_plot = df_plot.sort_values('epsilon_numeric')\n",
    "        # Create categorical column for model ordering\n",
    "        df_plot['modelname'] = pd.Categorical(df_plot['modelname'], categories=model_order, ordered=True)\n",
    "        df_plot = df_plot.sort_values(['epsilon_numeric', 'modelname'])\n",
    "    \n",
    "    return df_plot\n",
    "\n",
    "# Process all datasets\n",
    "wcsp_plot_data = process_dataset(wcsp_data, \"Warcraft\")\n",
    "\n",
    "# Create subplots with minimal spacing\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.07  # Minimize space between plots\n",
    ")\n",
    "\n",
    "# Colors for epsilon values - epsilon=8 uses same color as epsilon=0.05\n",
    "colors = {\n",
    "    'ε = 8': '#ff7f0e',  # Same color for both 0.05 and 8\n",
    "}\n",
    "\n",
    "# Add boxplots for each dataset\n",
    "datasets = [\n",
    "    (wcsp_plot_data, 1)\n",
    "]\n",
    "\n",
    "# Keep track of which epsilon values we've added to legend\n",
    "added_to_legend = set()\n",
    "\n",
    "for df_plot, row in datasets:\n",
    "    if not df_plot.empty:\n",
    "        for epsilon in df_plot['epsilon'].unique():\n",
    "            epsilon_data = df_plot[df_plot['epsilon'] == epsilon]\n",
    "            for modelname in epsilon_data['modelname'].unique():\n",
    "                model_data = epsilon_data[epsilon_data['modelname'] == modelname]\n",
    "                # Only show in legend if not already added\n",
    "                show_in_legend = epsilon not in added_to_legend\n",
    "                if show_in_legend:\n",
    "                    added_to_legend.add(epsilon)\n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Box(\n",
    "                        y=model_data['frre_value'],\n",
    "                        name=epsilon,\n",
    "                        x=[str(modelname)] * len(model_data),  # Ensure string for categorical\n",
    "                        marker_color=colors[epsilon],\n",
    "                        legendgroup=epsilon,\n",
    "                        showlegend=show_in_legend,\n",
    "                        offsetgroup=epsilon,\n",
    "                    ),\n",
    "                    row=row, col=1\n",
    "                )\n",
    "\n",
    "# Update layout with legend at bottom\n",
    "fig.update_annotations(font=dict(size=10))\n",
    "fig.update_layout(\n",
    "    boxmode='group',\n",
    "    template=\"plotly_white\",\n",
    "    width=600,\n",
    "    height=200,  # Reduced height since we minimized spacing\n",
    "    showlegend=False,\n",
    "    margin=dict(\n",
    "        l=10,   # Left margin\n",
    "        r=10,   # Right margin (reduced since legend is inside plot area)\n",
    "        t=20,   # Top margin\n",
    "        b=50    # Bottom margin (for x-axis label)\n",
    "    ),\n",
    ")\n",
    "# For single plots do not show the title \n",
    "fig.update_xaxes(tickfont_size=10)\n",
    "fig.update_yaxes(tickfont_size=10)\n",
    "\n",
    "# Update axes - shared y-axis title on middle subplot only # change size to 10\n",
    "fig.update_yaxes(title_text=\"FRRE\", row=1)\n",
    "fig.update_xaxes(title_text=\"Model\", row=1)\n",
    "\n",
    "# Set categorical x-axis ordering for all subplots\n",
    "for row in [0]:\n",
    "    fig.update_xaxes(categoryorder='array', categoryarray=model_order, row=row)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ababee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "path = \"\"\n",
    "fig.write_image(\"/storage/work/schaetz/plots/comparison_boxplots_wcsp.pdf\", format=\"pdf\", width=600, height=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robust-dfl (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
